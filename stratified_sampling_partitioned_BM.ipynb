{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from conformation_encode.scaffold_split import scaffold_split  \n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold \n",
    "def search_elements_in_dataframe(df, smiles_column, element_symbol):\n",
    "    found_indices = []\n",
    "    for index, row in df.iterrows():\n",
    "        smiles = row[smiles_column]\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol and any(atom.GetSymbol() == element_symbol for atom in mol.GetAtoms()):\n",
    "            found_indices.append(index)\n",
    "    return found_indices\n",
    "\n",
    "data_cdr1 = pd.read_csv(\"./data/Official/cdr1_binary_0902.csv\")\n",
    "se_indices = search_elements_in_dataframe(data_cdr1, \"Canonicalsmiles\", \"Se\")\n",
    "te_indices = search_elements_in_dataframe(data_cdr1, \"Canonicalsmiles\", \"Te\")\n",
    "error_index = se_indices+te_indices \n",
    "data_cdr1 = data_cdr1.drop(error_index, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k5/1m57zwdx4rg_gqk0zr7t2mx00000gn/T/ipykernel_10421/2111051895.py:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  rdk7 = pd.read_csv(rdk7_path)\n",
      "/var/folders/k5/1m57zwdx4rg_gqk0zr7t2mx00000gn/T/ipykernel_10421/2111051895.py:9: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  rdk5 = pd.read_csv(rdk5_path)\n",
      "/var/folders/k5/1m57zwdx4rg_gqk0zr7t2mx00000gn/T/ipykernel_10421/2111051895.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  rdk6 = pd.read_csv(rdk6_path)\n",
      "/var/folders/k5/1m57zwdx4rg_gqk0zr7t2mx00000gn/T/ipykernel_10421/2111051895.py:13: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ph4 = pd.read_csv(ph4_path)\n",
      "/var/folders/k5/1m57zwdx4rg_gqk0zr7t2mx00000gn/T/ipykernel_10421/2111051895.py:14: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  avalon = pd.read_csv(avalon_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Standardize_smile</th>\n",
       "      <th>Activity</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isonitrile_1</td>\n",
       "      <td>[C-]#[N+]C1=CC(=CCC(=O)O)CC1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WK14</td>\n",
       "      <td>Oc1ccccc1/C=C/c1ccc2cccc(O)c2n1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WK14B</td>\n",
       "      <td>CC(=O)Oc1ccccc1/C=C/c1ccc2cccc(OC(C)=O)c2n1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WK15</td>\n",
       "      <td>Oc1cccc(/C=C/c2ccc3cccc(O)c3n2)c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WK15B</td>\n",
       "      <td>CC(=O)Oc1cccc(/C=C/c2ccc3cccc(O)c3n2)c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4099 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                            Standardize_smile  Activity  0  1  \\\n",
       "0  Isonitrile_1                 [C-]#[N+]C1=CC(=CCC(=O)O)CC1         1  0  0   \n",
       "1          WK14              Oc1ccccc1/C=C/c1ccc2cccc(O)c2n1         1  0  0   \n",
       "2         WK14B  CC(=O)Oc1ccccc1/C=C/c1ccc2cccc(OC(C)=O)c2n1         1  0  0   \n",
       "3          WK15            Oc1cccc(/C=C/c2ccc3cccc(O)c3n2)c1         0  0  0   \n",
       "4         WK15B      CC(=O)Oc1cccc(/C=C/c2ccc3cccc(O)c3n2)c1         0  0  0   \n",
       "\n",
       "   2  3  4  5  6  ...  4086  4087  4088  4089  4090  4091  4092  4093  4094  \\\n",
       "0  0  0  0  0  0  ...     1     0     0     0     0     0     0     0     0   \n",
       "1  0  0  0  1  0  ...     0     0     0     0     0     0     0     0     0   \n",
       "2  0  0  0  1  0  ...     0     0     0     1     0     0     0     1     0   \n",
       "3  0  0  0  1  0  ...     0     0     0     0     0     0     0     0     0   \n",
       "4  0  0  0  1  0  ...     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   4095  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "\n",
       "[5 rows x 4099 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdk7_path = \"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/Mol_Featurizer/Cdr1_featurized_scaffold/RDK7.csv\"\n",
    "rdk5_path = \"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/Mol_Featurizer/Cdr1_featurized_scaffold/RDK5.csv\"\n",
    "rdk6_path = \"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/Mol_Featurizer/Cdr1_featurized_scaffold/RDK6.csv\"\n",
    "avalon_path = \"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/Mol_Featurizer/Cdr1_featurized_scaffold/Avalon.csv\"\n",
    "mordred_path = \"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/Mol_Featurizer/Cdr1_featurized_scaffold/Mordred_preprocess.csv\"\n",
    "ph4_path = \"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/Mol_Featurizer/Cdr1_featurized_scaffold/Ph4_gobbi.csv\"\n",
    "rdk7 = pd.read_csv(rdk7_path)\n",
    "rdk5 = pd.read_csv(rdk5_path)\n",
    "rdk6 = pd.read_csv(rdk6_path)\n",
    "#mordred = pd.read_csv(mordred_path_fix)\n",
    "mordred = pd.read_csv(mordred_path)\n",
    "ph4 = pd.read_csv(ph4_path)\n",
    "avalon = pd.read_csv(avalon_path)\n",
    "rdk7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Drop low variance column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def remove_low_variance(df, threshold):\n",
    "    id_smile_df = df[[\"ID\", \"Standardize_smile\"]]\n",
    "    df = df.drop([\"ID\", \"Standardize_smile\"], axis = 1)\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(df)\n",
    "    feature = selector.get_support(indices = False)\n",
    "    feature[0]=True\n",
    "    df_drop = df.iloc[:, feature]\n",
    "    df_drop = pd.concat([id_smile_df, df_drop], axis = 1)\n",
    "    return df_drop\n",
    "\n",
    "avalon_remove_variance = remove_low_variance(avalon, 0.0)\n",
    "ph4_remove_variance = remove_low_variance(ph4, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Active/Inactive dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdk5_active = rdk5[rdk5[\"Activity\"]==1].reset_index(drop=True)\n",
    "rdk5_inactive = rdk5[rdk5[\"Activity\"]==0].reset_index(drop=True)\n",
    "rdk6_active = rdk6[rdk6[\"Activity\"]==1].reset_index(drop=True)\n",
    "rdk6_inactive = rdk6[rdk6[\"Activity\"]==0].reset_index(drop=True)\n",
    "rdk7_active = rdk7[rdk7[\"Activity\"]==1].reset_index(drop=True)\n",
    "rdk7_inactive = rdk7[rdk7[\"Activity\"]==0].reset_index(drop=True)\n",
    "mordred_active = mordred[mordred[\"Activity\"]==1].reset_index(drop=True)\n",
    "mordred_inactive = mordred[mordred[\"Activity\"]==0].reset_index(drop=True)\n",
    "ph4_active = ph4_remove_variance[ph4_remove_variance[\"Activity\"]==1].reset_index(drop=True)\n",
    "ph4_inactive = ph4_remove_variance[ph4_remove_variance[\"Activity\"]==0].reset_index(drop=True)\n",
    "avalon_active = avalon_remove_variance[avalon_remove_variance[\"Activity\"]==1].reset_index(drop=True)\n",
    "avalon_inactive = avalon_remove_variance[avalon_remove_variance[\"Activity\"]==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Check outlier inactive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from numpy import where, random\n",
    "def remove_outlier(df):\n",
    "    X = df.drop(['Activity',\"ID\",\"Standardize_smile\"], axis=1)\n",
    "    y = df['Activity'].values\n",
    "    lof = LocalOutlierFactor(n_neighbors=20)\n",
    "    y_pred = lof.fit_predict(X)\n",
    "    lofs_index = where(y_pred==-1)\n",
    "    print(f\"The number of outlier is {len(lofs_index[0])}\")\n",
    "    return lofs_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outlier is 37\n",
      "The number of outlier is 8\n",
      "The number of outlier is 0\n",
      "The number of outlier is 56\n",
      "The number of outlier is 1086\n",
      "The number of outlier is 1\n"
     ]
    }
   ],
   "source": [
    "rdk7_outlier_inacitve = remove_outlier(rdk7_inactive)\n",
    "rdk5_outlier_inactive = remove_outlier(rdk5_inactive)\n",
    "rdk6_outlier_inactive = remove_outlier(rdk6_inactive)\n",
    "mordred_outlier_inactive = remove_outlier(mordred_inactive)\n",
    "ph4_outlier_inactive = remove_outlier(ph4_inactive)\n",
    "avalon_outlier_inactive = remove_outlier(avalon_inactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique outlier inactive is 1108\n"
     ]
    }
   ],
   "source": [
    "#Check unique indices\n",
    "index_outlier_rdk5_inactive = {index for index in rdk5_outlier_inactive}\n",
    "index_outlier_rdk6_inactive = {index for index in rdk6_outlier_inactive}\n",
    "index_outlier_rdk7_inactive = {index for index in rdk7_outlier_inacitve}\n",
    "index_outlier_mordred_inactive = {index for index in mordred_outlier_inactive}\n",
    "index_outlier_ph4_inactive = {index for index in ph4_outlier_inactive}\n",
    "index_outlier_avalon_inactive = {index for index in avalon_outlier_inactive}\n",
    "unique_indices_inactive = index_outlier_rdk5_inactive.union(index_outlier_rdk6_inactive, index_outlier_rdk7_inactive, index_outlier_mordred_inactive, \n",
    "                                                            index_outlier_ph4_inactive, index_outlier_avalon_inactive)\n",
    "print(f\"The number of unique outlier inactive is {len(unique_indices_inactive)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outliers inactive\n",
    "rdk7_outlier_inactive_df = rdk7_inactive.iloc[list(unique_indices_inactive)].reset_index(drop=True)\n",
    "rdk5_outlier_inactive_df = rdk5_inactive.iloc[list(unique_indices_inactive)].reset_index(drop=True)\n",
    "rdk6_outlier_inactive_df = rdk6_inactive.iloc[list(unique_indices_inactive)].reset_index(drop=True)\n",
    "mordred_outlier_inactive_df = mordred_inactive.iloc[list(unique_indices_inactive)].reset_index(drop=True)\n",
    "ph4_outlier_inactive_df = ph4_inactive.iloc[list(unique_indices_inactive)].reset_index(drop=True)\n",
    "avalon_outlier_inactive_df = avalon_inactive.iloc[list(unique_indices_inactive)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving data inactive outliers\n",
    "rdk5_outlier_inactive_df.to_csv(\"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/data/Official/Featurizer_data/rdk5_hard_test.csv\", index=False)\n",
    "rdk6_outlier_inactive_df.to_csv(\"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/data/Official/Featurizer_data/rdk6_hard_test.csv\", index=False)\n",
    "rdk7_outlier_inactive_df.to_csv(\"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/data/Official/Featurizer_data/rdk7_hard_test.csv\", index=False)\n",
    "mordred_outlier_inactive_df.to_csv(\"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/data/Official/Featurizer_data/mordred_hard_test.csv\", index=False)\n",
    "ph4_outlier_inactive_df.to_csv(\"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/data/Official/Featurizer_data/ph4_hard_test.csv\", index=False)\n",
    "avalon_outlier_inactive_df.to_csv(\"/Users/thechuongtrinh/Documents/Workspace/Master_thesis/Cdr1/data/Official/Featurizer_data/avalon_hard_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal inactive\n",
    "rdk7_inactive_df = rdk7_inactive.drop(list(unique_indices_inactive), axis = 0).reset_index(drop=True)\n",
    "rdk5_inactive_df = rdk5_inactive.drop(list(unique_indices_inactive), axis = 0).reset_index(drop=True)\n",
    "rdk6_inactive_df = rdk6_inactive.drop(list(unique_indices_inactive), axis = 0).reset_index(drop=True)\n",
    "mordred_inactive_df = mordred_inactive.drop(list(unique_indices_inactive), axis = 0).reset_index(drop=True)\n",
    "ph4_inactive_df = ph4_inactive.drop(list(unique_indices_inactive), axis = 0).reset_index(drop=True)\n",
    "avalon_inactive_df = avalon_inactive.drop(list(unique_indices_inactive), axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Check outlier active**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outlier is 0\n",
      "The number of outlier is 0\n",
      "The number of outlier is 0\n",
      "The number of outlier is 4\n",
      "The number of outlier is 34\n",
      "The number of outlier is 0\n"
     ]
    }
   ],
   "source": [
    "rdk7_outlier_acitve = remove_outlier(rdk7_active)\n",
    "rdk5_outlier_active = remove_outlier(rdk5_active)\n",
    "rdk6_outlier_active = remove_outlier(rdk6_active)\n",
    "mordred_outlier_active = remove_outlier(mordred_active)\n",
    "ph4_outlier_active = remove_outlier(ph4_active)\n",
    "avalon_outlier_active = remove_outlier(avalon_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique outlier active is 36\n"
     ]
    }
   ],
   "source": [
    "#Check unique indices\n",
    "index_outlier_rdk5_active = {index for index in rdk5_outlier_active}\n",
    "index_outlier_rdk6_active = {index for index in rdk6_outlier_active}\n",
    "index_outlier_rdk7_active = {index for index in rdk7_outlier_acitve}\n",
    "index_outlier_mordred_active = {index for index in mordred_outlier_active}\n",
    "index_outlier_ph4_active = {index for index in ph4_outlier_active}\n",
    "index_outlier_avalon_active = {index for index in avalon_outlier_active}\n",
    "unique_indices_active = index_outlier_rdk5_active.union(index_outlier_rdk6_active, index_outlier_rdk7_active, index_outlier_mordred_active, \n",
    "                                                            index_outlier_ph4_active, index_outlier_avalon_active)\n",
    "print(f\"The number of unique outlier active is {len(unique_indices_active)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outliers active\n",
    "rdk7_outlier_active_df = rdk7_active.iloc[list(unique_indices_active)].reset_index(drop=True)\n",
    "rdk5_outlier_active_df = rdk5_active.iloc[list(unique_indices_active)].reset_index(drop=True)\n",
    "rdk6_outlier_active_df = rdk6_active.iloc[list(unique_indices_active)].reset_index(drop=True)\n",
    "mordred_outlier_active_df = mordred_active.iloc[list(unique_indices_active)].reset_index(drop=True)\n",
    "ph4_outlier_active_df = ph4_active.iloc[list(unique_indices_active)].reset_index(drop=True)\n",
    "avalon_outlier_active_df = avalon_active.iloc[list(unique_indices_active)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal active\n",
    "rdk7_active_df = rdk7_active.drop(list(unique_indices_active), axis = 0).reset_index(drop=True)\n",
    "rdk5_active_df = rdk5_active.drop(list(unique_indices_active), axis = 0).reset_index(drop=True)\n",
    "rdk6_active_df = rdk6_active.drop(list(unique_indices_active), axis = 0).reset_index(drop=True)\n",
    "mordred_active_df = mordred_active.drop(list(unique_indices_active), axis = 0).reset_index(drop=True)\n",
    "ph4_active_df = ph4_active.drop(list(unique_indices_active), axis = 0).reset_index(drop=True)\n",
    "avalon_active_df = avalon_active.drop(list(unique_indices_active), axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdk7_active_df.to_csv(\"rdk7_normal_active.csv\", index = False)\n",
    "rdk7_outlier_active_df.to_csv(\"rdk7_outliers_active.csv\", index= False)\n",
    "rdk7_inactive_df.to_csv(\"rdk7_inactive_normal.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Splitting data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting data\n",
    "def splitting_data(data, test_size, valid_size ,seed):\n",
    "    data_train, data_test = scaffold_split(data, smiles_col = \"Standardize_smile\", test_size = test_size,random_state = seed)\n",
    "    data_train = data_train.reset_index(drop=True)\n",
    "    data_test = data_test.reset_index(drop=True)\n",
    "    data_train, data_valid = scaffold_split(data_train, smiles_col = \"Standardize_smile\", test_size = valid_size,random_state = seed)\n",
    "    data_train = data_train.reset_index(drop=True)\n",
    "    data_valid = data_valid.reset_index(drop=True)\n",
    "    return data_train, data_valid, data_test\n",
    "\n",
    "train_active_rdk7, valid_active_rdk7, test_active_rdk7 = splitting_data(rdk7_active_df, 0.341, 0.323, 42)\n",
    "train_inactive_rdk7, valid_inactive_rdk7, test_inactive_rdk7 = splitting_data(rdk7_inactive_df, 0.252, 0.2, 42)\n",
    "train_rdk7 = pd.concat([train_active_rdk7, train_inactive_rdk7, rdk7_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "test_rdk7 = pd.concat([test_active_rdk7, test_inactive_rdk7], axis = 0).reset_index(drop=True)\n",
    "valid_rdk7 = pd.concat([valid_active_rdk7, valid_inactive_rdk7], axis = 0).reset_index(drop=True)\n",
    "\n",
    "train_active_rdk5, valid_active_rdk5, test_active_rdk5 = splitting_data(rdk5_active_df, 0.341, 0.323, 42)\n",
    "train_inactive_rdk5, valid_inactive_rdk5, test_inactive_rdk5 = splitting_data(rdk5_inactive_df, 0.252, 0.2, 42)\n",
    "train_rdk5 = pd.concat([train_active_rdk5, train_inactive_rdk5, rdk5_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "test_rdk5 = pd.concat([test_active_rdk5, test_inactive_rdk5], axis = 0).reset_index(drop=True)\n",
    "valid_rdk5 = pd.concat([valid_active_rdk5, valid_inactive_rdk5], axis = 0).reset_index(drop=True)\n",
    "\n",
    "train_active_rdk6, valid_active_rdk6, test_active_rdk6 = splitting_data(rdk6_active_df, 0.341, 0.323, 42)\n",
    "train_inactive_rdk6, valid_inactive_rdk6, test_inactive_rdk6 = splitting_data(rdk6_inactive_df, 0.252, 0.2, 42)\n",
    "train_rdk6 = pd.concat([train_active_rdk6, train_inactive_rdk6, rdk6_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "test_rdk6 = pd.concat([test_active_rdk6, test_inactive_rdk6], axis = 0).reset_index(drop=True)\n",
    "valid_rdk6 = pd.concat([valid_active_rdk6, valid_inactive_rdk6], axis = 0).reset_index(drop=True)\n",
    "\n",
    "train_active_mordred, valid_active_mordred, test_active_mordred = splitting_data(mordred_active_df, 0.341, 0.323, 42)\n",
    "train_inactive_mordred, valid_inactive_mordred, test_inactive_mordred = splitting_data(mordred_inactive_df, 0.252, 0.2, 42)\n",
    "train_mordred = pd.concat([train_active_mordred, train_inactive_mordred, mordred_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "test_mordred = pd.concat([test_active_mordred, test_inactive_mordred], axis = 0).reset_index(drop=True)\n",
    "valid_mordred = pd.concat([valid_active_mordred, valid_inactive_mordred], axis = 0).reset_index(drop=True)\n",
    "\n",
    "train_active_ph4, valid_active_ph4, test_active_ph4 = splitting_data(ph4_active_df, 0.341, 0.323, 42)\n",
    "train_inactive_ph4, valid_inactive_ph4, test_inactive_ph4 = splitting_data(ph4_inactive_df, 0.252, 0.2, 42)\n",
    "train_ph4 = pd.concat([train_active_ph4, train_inactive_ph4, ph4_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "test_ph4 = pd.concat([test_active_ph4, test_inactive_ph4], axis = 0).reset_index(drop=True)\n",
    "valid_ph4 = pd.concat([valid_active_ph4, valid_inactive_ph4], axis = 0).reset_index(drop=True)\n",
    "\n",
    "train_active_avalon, valid_active_avalon, test_active_avalon = splitting_data(avalon_active_df, 0.341, 0.323, 42)\n",
    "train_inactive_avalon, valid_inactive_avalon, test_inactive_avalon = splitting_data(avalon_inactive_df, 0.252, 0.2, 42)\n",
    "train_avalon = pd.concat([train_active_avalon, train_inactive_avalon, avalon_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "test_avalon = pd.concat([test_active_avalon, test_inactive_avalon], axis = 0).reset_index(drop=True)\n",
    "valid_avalon = pd.concat([valid_active_avalon, valid_inactive_avalon], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Splitting  active outlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 49 is duplicated\n",
      "Index 53 is duplicated\n",
      "Index 57 is duplicated\n",
      "Index 63 is duplicated\n",
      "Index 64 is duplicated\n",
      "Index 68 is duplicated\n",
      "Index 69 is duplicated\n",
      "Index 71 is duplicated\n",
      "Index 74 is duplicated\n",
      "Index 77 is duplicated\n"
     ]
    }
   ],
   "source": [
    "rdk7_active = pd.concat([train_active_rdk7,rdk7_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "data = rdk7_active\n",
    "scaffolds = {}\n",
    "for idx, row in data.iterrows():\n",
    "    smiles = row[\"Standardize_smile\"]\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    scaffold = MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=False)\n",
    "    if scaffold not in scaffolds:\n",
    "        scaffolds[scaffold] = [idx]\n",
    "    elif scaffold in scaffolds and idx >= 42:\n",
    "        print(f\"Index {idx} is duplicated\")\n",
    "        scaffolds[scaffold].append(idx)\n",
    "    else:\n",
    "        scaffolds[scaffold].append(idx)\n",
    "scaffold_lists = list(scaffolds.values()) #Scaffolds in active outliers are different scaffolds in normal active data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_folds_active(data, seed):\n",
    "    fold_1_2_3, fold_4 = scaffold_split(data, smiles_col = \"Standardize_smile\", test_size = 0.25, random_state = seed)\n",
    "    fold_1_2_3 = fold_1_2_3.reset_index(drop=True)\n",
    "    fold_4 = fold_4.reset_index(drop=True)\n",
    "    fold_1_2, fold_3 = scaffold_split(fold_1_2_3, smiles_col = \"Standardize_smile\", test_size = 0.33, random_state = seed)\n",
    "    fold_1_2 = fold_1_2.reset_index(drop=True)\n",
    "    fold_3 = fold_3.reset_index(drop=True)\n",
    "    fold_1, fold_2 = scaffold_split(fold_1_2, smiles_col = \"Standardize_smile\", test_size = 0.5, random_state = seed)\n",
    "    fold_1 = fold_1.reset_index(drop=True)\n",
    "    fold_2 = fold_2.reset_index(drop=True)\n",
    "    return fold_1, fold_2, fold_3, fold_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_folds_inactive(data, seed):\n",
    "    fold_1_2_3, fold_4 = scaffold_split(data, smiles_col = \"Standardize_smile\", test_size = 0.25, random_state = seed)\n",
    "    fold_1_2_3 = fold_1_2_3.reset_index(drop=True)\n",
    "    fold_4 = fold_4.reset_index(drop=True)\n",
    "    fold_1_2, fold_3 = scaffold_split(fold_1_2_3, smiles_col = \"Standardize_smile\", test_size = 0.333, random_state = seed)\n",
    "    fold_1_2 = fold_1_2.reset_index(drop=True)\n",
    "    fold_3 = fold_3.reset_index(drop=True)\n",
    "    fold_1, fold_2 = scaffold_split(fold_1_2, smiles_col = \"Standardize_smile\", test_size = 0.5, random_state = seed)\n",
    "    fold_1 = fold_1.reset_index(drop=True)\n",
    "    fold_2 = fold_2.reset_index(drop=True)\n",
    "    return fold_1, fold_2, fold_3, fold_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active fold 1: 20\n",
      "Active fold 2: 20\n",
      "Active fold 3: 19\n",
      "Active fold 4: 19\n",
      "Inactive fold 1: 87\n",
      "Inactive fold 2: 86\n",
      "Inactive fold 3: 86\n",
      "Inactive fold 4: 86\n"
     ]
    }
   ],
   "source": [
    "fold_1_active_rdk7, fold_2_active_rdk7, fold_3_active_rdk7, fold_4_active_rdk7 = spliting_folds_active(rdk7_active, 42)\n",
    "print(f\"Active fold 1: {fold_1_active_rdk7.shape[0]}\")\n",
    "print(f\"Active fold 2: {fold_2_active_rdk7.shape[0]}\")\n",
    "print(f\"Active fold 3: {fold_3_active_rdk7.shape[0]}\")\n",
    "print(f\"Active fold 4: {fold_4_active_rdk7.shape[0]}\")\n",
    "fold_1_inactive_rdk7, fold_2_inactive_rdk7, fold_3_inactive_rdk7, fold_4_inactive_rdk7 = spliting_folds_inactive(train_inactive_rdk7, 42)\n",
    "print(f\"Inactive fold 1: {fold_1_inactive_rdk7.shape[0]}\")\n",
    "print(f\"Inactive fold 2: {fold_2_inactive_rdk7.shape[0]}\")\n",
    "print(f\"Inactive fold 3: {fold_3_inactive_rdk7.shape[0]}\")\n",
    "print(f\"Inactive fold 4: {fold_4_inactive_rdk7.shape[0]}\")\n",
    "fold_1_rdk7 = pd.concat([fold_1_active_rdk7, fold_1_inactive_rdk7], axis = 0).reset_index(drop=True)\n",
    "fold_2_rdk7 = pd.concat([fold_2_active_rdk7, fold_2_inactive_rdk7], axis = 0).reset_index(drop=True)\n",
    "fold_3_rdk7 = pd.concat([fold_3_active_rdk7, fold_3_inactive_rdk7], axis = 0).reset_index(drop=True)\n",
    "fold_4_rdk7 = pd.concat([fold_4_active_rdk7, fold_4_inactive_rdk7], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fold_1_path = \"./data/Official/Featurizer_data/fold_1/\"\n",
    "os.makedirs(fold_1_path, exist_ok=True)\n",
    "fold_2_path = \"./data/Official/Featurizer_data/fold_2/\"\n",
    "os.makedirs(fold_2_path, exist_ok=True)\n",
    "fold_3_path = \"./data/Official/Featurizer_data/fold_3/\"\n",
    "os.makedirs(fold_3_path, exist_ok=True)\n",
    "fold_4_path = \"./data/Official/Featurizer_data/fold_4/\"\n",
    "os.makedirs(fold_4_path, exist_ok=True)\n",
    "\n",
    "fold_1_rdk7.to_csv(f\"{fold_1_path}rdk7.csv\", index=False)\n",
    "fold_2_rdk7.to_csv(f\"{fold_2_path}rdk7.csv\", index=False)\n",
    "fold_3_rdk7.to_csv(f\"{fold_3_path}rdk7.csv\", index=False)\n",
    "fold_4_rdk7.to_csv(f\"{fold_4_path}rdk7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "def create_scaffold_df(data):\n",
    "    scaffolds = {}\n",
    "    for idx, row in data.iterrows():\n",
    "        smiles = row[\"Standardize_smile\"]\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        scaffold = MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=False)\n",
    "        if scaffold not in scaffolds:\n",
    "            scaffolds[scaffold] = [idx]\n",
    "        else:\n",
    "            scaffolds[scaffold].append(idx)\n",
    "    scaffold_clean = [x for x in list(scaffolds.keys()) if x!= '']\n",
    "    df_dict = {\"ID\": [], \"Scaffold\": scaffold_clean, \"Activity\": []}\n",
    "    df_dict[\"Activity\"] = [1 if any(data.loc[scaffolds[scaffold], \"Activity\"]==1) else 0 for scaffold in scaffold_clean]\n",
    "    df_dict[\"ID\"] = [x for x in range(len(scaffold_clean))]\n",
    "    df_scaffold = pd.DataFrame(df_dict)\n",
    "    return df_scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are scaffolds in fold 1 active are also in active outliers 8\n",
      "There are scaffolds in fold 2 active are also in active outliers 3\n",
      "There are scaffolds in fold 3 active are also in active outliers 11\n",
      "There are scaffolds in fold 4 active are also in active outliers 6\n",
      "There are no scaffolds in fold 5 active are also in active outliers\n"
     ]
    }
   ],
   "source": [
    "#Fold 1\n",
    "active_outliers_scaffold = list(create_scaffold_df(rdk7_outlier_active_df)[\"Scaffold\"].values)\n",
    "fold_1_active_scaffold = create_scaffold_df(fold_1_active_rdk7)\n",
    "result = fold_1_active_scaffold['Scaffold'].isin(active_outliers_scaffold)\n",
    "if any(result):\n",
    "    print(f\"There are scaffolds in fold 1 active are also in active outliers {result.sum()}\")\n",
    "else: \n",
    "    print(\"There are no scaffolds in fold 1 active are also in active outliers\")\n",
    "#Fold 2\n",
    "fold_2_active_scaffold = create_scaffold_df(fold_2_active_rdk7)\n",
    "result = fold_2_active_scaffold['Scaffold'].isin(active_outliers_scaffold)\n",
    "if any(result):\n",
    "    print(f\"There are scaffolds in fold 2 active are also in active outliers {result.sum()}\")\n",
    "else:\n",
    "    print(\"There are no scaffolds in fold 2 active are also in active outliers\")\n",
    "#Fold 3\n",
    "fold_3_active_scaffold = create_scaffold_df(fold_3_active_rdk7)\n",
    "result = fold_3_active_scaffold['Scaffold'].isin(active_outliers_scaffold)\n",
    "if any(result):\n",
    "    print(f\"There are scaffolds in fold 3 active are also in active outliers {result.sum()}\")\n",
    "else:\n",
    "    print(\"There are no scaffolds in fold 3 active are also in active outliers\")\n",
    "#Fold 4\n",
    "fold_4_active_scaffold = create_scaffold_df(fold_4_active_rdk7)\n",
    "result = fold_4_active_scaffold['Scaffold'].isin(active_outliers_scaffold)\n",
    "if any(result):\n",
    "    print(f\"There are scaffolds in fold 4 active are also in active outliers {result.sum()}\")\n",
    "else:\n",
    "    print(\"There are no scaffolds in fold 4 active are also in active outliers\")\n",
    "#Fold 5:\n",
    "fold_5_active_scaffold = create_scaffold_df(valid_rdk7)\n",
    "result = fold_5_active_scaffold['Scaffold'].isin(active_outliers_scaffold)\n",
    "if any(result):\n",
    "    print(f\"There are scaffolds in fold 5 active are also in active outliers {result.sum()}\")\n",
    "else:\n",
    "    print(\"There are no scaffolds in fold 5 active are also in active outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdk7_train = pd.concat([fold_1_rdk7, fold_2_rdk7, fold_3_rdk7, fold_4_rdk7], axis = 0).reset_index(drop=True)\n",
    "rdk7_test = test_rdk7\n",
    "rdk7_valid = valid_rdk7\n",
    "rdk7_train.to_csv(\"./data/Official/Featurizer_data/rdk7_train.csv\", index = False)\n",
    "rdk7_test.to_csv(\"./data/Official/Featurizer_data/rdk7_test.csv\", index = False)\n",
    "rdk7_valid.to_csv(\"./data/Official/Featurizer_data/rdk7_valid.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdk5_active = pd.concat([train_active_rdk5, rdk5_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "rdk6_active = pd.concat([train_active_rdk6, rdk6_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "mordred_active = pd.concat([train_active_mordred, mordred_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "ph4_active = pd.concat([train_active_ph4, ph4_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "avalon_active = pd.concat([train_active_avalon, avalon_outlier_active_df], axis = 0).reset_index(drop=True)\n",
    "\n",
    "fold_1_active_rdk5, fold_2_active_rdk5, fold_3_active_rdk5, fold_4_active_rdk5 = spliting_folds_active(rdk5_active, 42)\n",
    "fold_1_active_rdk6, fold_2_active_rdk6, fold_3_active_rdk6, fold_4_active_rdk6 = spliting_folds_active(rdk6_active, 42)\n",
    "fold_1_active_mordred, fold_2_active_mordred, fold_3_active_mordred, fold_4_active_mordred = spliting_folds_active(mordred_active, 42)\n",
    "fold_1_active_ph4, fold_2_active_ph4, fold_3_active_ph4, fold_4_active_ph4 = spliting_folds_active(ph4_active, 42)\n",
    "fold_1_active_avalon, fold_2_active_avalon, fold_3_active_avalon, fold_4_active_avalon = spliting_folds_active(avalon_active, 42)\n",
    "fold_1_active_rdk7, fold_2_active_rdk7, fold_3_active_rdk7, fold_4_active_rdk7 = spliting_folds_active(rdk7_active, 42)\n",
    "\n",
    "fold_1_inactive_rdk5, fold_2_inactive_rdk5, fold_3_inactive_rdk5, fold_4_inactive_rdk5 = spliting_folds_inactive(train_inactive_rdk5, 42)\n",
    "fold_1_inactive_rdk6, fold_2_inactive_rdk6, fold_3_inactive_rdk6, fold_4_inactive_rdk6 = spliting_folds_inactive(train_inactive_rdk6, 42)\n",
    "fold_1_inactive_mordred, fold_2_inactive_mordred, fold_3_inactive_mordred, fold_4_inactive_mordred = spliting_folds_inactive(train_inactive_mordred, 42)\n",
    "fold_1_inactive_ph4, fold_2_inactive_ph4, fold_3_inactive_ph4, fold_4_inactive_ph4 = spliting_folds_inactive(train_inactive_ph4, 42)\n",
    "fold_1_inactive_avalon, fold_2_inactive_avalon, fold_3_inactive_avalon, fold_4_inactive_avalon = spliting_folds_inactive(train_inactive_avalon, 42)\n",
    "\n",
    "fold_1_rdk5 = pd.concat([fold_1_active_rdk5, fold_1_inactive_rdk5], axis = 0).reset_index(drop=True)\n",
    "fold_2_rdk5 = pd.concat([fold_2_active_rdk5, fold_2_inactive_rdk5], axis = 0).reset_index(drop=True)\n",
    "fold_3_rdk5 = pd.concat([fold_3_active_rdk5, fold_3_inactive_rdk5], axis = 0).reset_index(drop=True)\n",
    "fold_4_rdk5 = pd.concat([fold_4_active_rdk5, fold_4_inactive_rdk5], axis = 0).reset_index(drop=True)\n",
    "\n",
    "fold_1_rdk6 = pd.concat([fold_1_active_rdk6, fold_1_inactive_rdk6], axis = 0).reset_index(drop=True)\n",
    "fold_2_rdk6 = pd.concat([fold_2_active_rdk6, fold_2_inactive_rdk6], axis = 0).reset_index(drop=True)\n",
    "fold_3_rdk6 = pd.concat([fold_3_active_rdk6, fold_3_inactive_rdk6], axis = 0).reset_index(drop=True)\n",
    "fold_4_rdk6 = pd.concat([fold_4_active_rdk6, fold_4_inactive_rdk6], axis = 0).reset_index(drop=True)\n",
    "\n",
    "fold_1_mordred = pd.concat([fold_1_active_mordred, fold_1_inactive_mordred], axis = 0).reset_index(drop=True)\n",
    "fold_2_mordred = pd.concat([fold_2_active_mordred, fold_2_inactive_mordred], axis = 0).reset_index(drop=True)\n",
    "fold_3_mordred = pd.concat([fold_3_active_mordred, fold_3_inactive_mordred], axis = 0).reset_index(drop=True)\n",
    "fold_4_mordred = pd.concat([fold_4_active_mordred, fold_4_inactive_mordred], axis = 0).reset_index(drop=True)\n",
    "\n",
    "fold_1_ph4 = pd.concat([fold_1_active_ph4, fold_1_inactive_ph4], axis = 0).reset_index(drop=True)\n",
    "fold_2_ph4 = pd.concat([fold_2_active_ph4, fold_2_inactive_ph4], axis = 0).reset_index(drop=True)\n",
    "fold_3_ph4 = pd.concat([fold_3_active_ph4, fold_3_inactive_ph4], axis = 0).reset_index(drop=True)\n",
    "fold_4_ph4 = pd.concat([fold_4_active_ph4, fold_4_inactive_ph4], axis = 0).reset_index(drop=True)\n",
    "\n",
    "fold_1_avalon = pd.concat([fold_1_active_avalon, fold_1_inactive_avalon], axis = 0).reset_index(drop=True)\n",
    "fold_2_avalon = pd.concat([fold_2_active_avalon, fold_2_inactive_avalon], axis = 0).reset_index(drop=True)\n",
    "fold_3_avalon = pd.concat([fold_3_active_avalon, fold_3_inactive_avalon], axis = 0).reset_index(drop=True)\n",
    "fold_4_avalon = pd.concat([fold_4_active_avalon, fold_4_inactive_avalon], axis = 0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdk5_train = pd.concat([fold_1_rdk5, fold_2_rdk5, fold_3_rdk5, fold_4_rdk5], axis = 0).reset_index(drop=True)\n",
    "rdk5_test = test_rdk5\n",
    "rdk5_valid = valid_rdk5\n",
    "rdk5_train.to_csv(\"./data/Official/Featurizer_data/rdk5_train.csv\", index = False)\n",
    "rdk5_test.to_csv(\"./data/Official/Featurizer_data/rdk5_test.csv\", index = False)\n",
    "rdk5_valid.to_csv(\"./data/Official/Featurizer_data/rdk5_valid.csv\", index = False)\n",
    "\n",
    "fold_1_rdk5.to_csv(f\"{fold_1_path}rdk5.csv\", index=False)\n",
    "fold_2_rdk5.to_csv(f\"{fold_2_path}rdk5.csv\", index=False)\n",
    "fold_3_rdk5.to_csv(f\"{fold_3_path}rdk5.csv\", index=False)\n",
    "fold_4_rdk5.to_csv(f\"{fold_4_path}rdk5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdk6_train = pd.concat([fold_1_rdk6, fold_2_rdk6, fold_3_rdk6, fold_4_rdk6], axis = 0).reset_index(drop=True)\n",
    "rdk6_test = test_rdk6\n",
    "rdk6_valid = valid_rdk6\n",
    "rdk6_train.to_csv(\"./data/Official/Featurizer_data/rdk6_train.csv\", index = False)\n",
    "rdk6_test.to_csv(\"./data/Official/Featurizer_data/rdk6_test.csv\", index = False)\n",
    "rdk6_valid.to_csv(\"./data/Official/Featurizer_data/rdk6_valid.csv\", index = False)\n",
    "\n",
    "fold_1_rdk6.to_csv(f\"{fold_1_path}rdk6.csv\", index=False)\n",
    "fold_2_rdk6.to_csv(f\"{fold_2_path}rdk6.csv\", index=False)\n",
    "fold_3_rdk6.to_csv(f\"{fold_3_path}rdk6.csv\", index=False)\n",
    "fold_4_rdk6.to_csv(f\"{fold_4_path}rdk6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "mordred_train = pd.concat([fold_1_mordred, fold_2_mordred, fold_3_mordred, fold_4_mordred], axis = 0).reset_index(drop=True)\n",
    "mordred_test = test_mordred\n",
    "mordred_valid = valid_mordred\n",
    "mordred_train.to_csv(\"./data/Official/Featurizer_data/mordred_train.csv\", index = False)\n",
    "mordred_test.to_csv(\"./data/Official/Featurizer_data/mordred_test.csv\", index = False)\n",
    "mordred_valid.to_csv(\"./data/Official/Featurizer_data/mordred_valid.csv\", index = False)\n",
    "\n",
    "fold_1_mordred.to_csv(f\"{fold_1_path}mordred.csv\", index=False)\n",
    "fold_2_mordred.to_csv(f\"{fold_2_path}mordred.csv\", index=False)\n",
    "fold_3_mordred.to_csv(f\"{fold_3_path}mordred.csv\", index=False) \n",
    "fold_4_mordred.to_csv(f\"{fold_4_path}mordred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalon_train = pd.concat([fold_1_avalon, fold_2_avalon, fold_3_avalon, fold_4_avalon], axis = 0).reset_index(drop=True)\n",
    "avalon_test = test_avalon\n",
    "avalon_valid = valid_avalon\n",
    "avalon_train.to_csv(\"./data/Official/Featurizer_data/avalon_train.csv\", index = False)\n",
    "avalon_test.to_csv(\"./data/Official/Featurizer_data/avalon_test.csv\", index = False)\n",
    "avalon_valid.to_csv(\"./data/Official/Featurizer_data/avalon_valid.csv\", index = False)\n",
    "\n",
    "fold_1_avalon.to_csv(f\"{fold_1_path}avalon.csv\", index=False)\n",
    "fold_2_avalon.to_csv(f\"{fold_2_path}avalon.csv\", index=False)\n",
    "fold_3_avalon.to_csv(f\"{fold_3_path}avalon.csv\", index=False)\n",
    "fold_4_avalon.to_csv(f\"{fold_4_path}avalon.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph4_train = pd.concat([fold_1_ph4, fold_2_ph4, fold_3_ph4, fold_4_ph4], axis = 0).reset_index(drop=True)\n",
    "ph4_test = test_ph4\n",
    "ph4_valid = valid_ph4\n",
    "ph4_train.to_csv(\"./data/Official/Featurizer_data/ph4_train.csv\", index = False)\n",
    "ph4_test.to_csv(\"./data/Official/Featurizer_data/ph4_test.csv\", index = False)\n",
    "ph4_valid.to_csv(\"./data/Official/Featurizer_data/ph4_valid.csv\", index = False)\n",
    "\n",
    "fold_1_ph4.to_csv(f\"{fold_1_path}ph4.csv\", index=False)\n",
    "fold_2_ph4.to_csv(f\"{fold_2_path}ph4.csv\", index=False)\n",
    "fold_3_ph4.to_csv(f\"{fold_3_path}ph4.csv\", index=False)\n",
    "fold_4_ph4.to_csv(f\"{fold_4_path}ph4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BM scaffold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "def create_scaffold_df(data):\n",
    "    scaffolds = {}\n",
    "    for idx, row in data.iterrows():\n",
    "        smiles = row[\"Standardize_smile\"]\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        scaffold = MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=False)\n",
    "        if scaffold not in scaffolds:\n",
    "            scaffolds[scaffold] = [idx]\n",
    "        else:\n",
    "            scaffolds[scaffold].append(idx)\n",
    "    scaffold_clean = [x for x in list(scaffolds.keys()) if x!= '']\n",
    "    df_dict = {\"ID\": [], \"Scaffold\": scaffold_clean, \"Activity\": []}\n",
    "    df_dict[\"Activity\"] = [1 if any(data.loc[scaffolds[scaffold], \"Activity\"]==1) else 0 for scaffold in scaffold_clean]\n",
    "    df_dict[\"ID\"] = [x for x in range(len(scaffold_clean))]\n",
    "    df_scaffold = pd.DataFrame(df_dict)\n",
    "    return df_scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scaffold(data_train, data_valid, data_test):\n",
    "    active_train_df = data_train[data_train[\"Activity\"]==1]\n",
    "    active_train_scaffold = create_scaffold_df(active_train_df)\n",
    "    inactive_train_df = data_train[data_train[\"Activity\"]==0]\n",
    "    inactive_train_scaffold = create_scaffold_df(inactive_train_df)\n",
    "    active_valid_df = data_valid[data_valid[\"Activity\"]==1]\n",
    "    active_valid_scaffold = create_scaffold_df(active_valid_df)\n",
    "    inactive_valid_df = data_valid[data_valid[\"Activity\"]==0]\n",
    "    inactive_valid_scaffold = create_scaffold_df(inactive_valid_df)\n",
    "    active_test_df = data_test[data_test[\"Activity\"]==1]\n",
    "    active_test_scaffold = create_scaffold_df(active_test_df)\n",
    "    inactive_test_df = data_test[data_test[\"Activity\"]==0]\n",
    "    inactive_test_scaffold = create_scaffold_df(inactive_test_df)\n",
    "    return active_train_scaffold, inactive_train_scaffold, active_valid_scaffold, inactive_valid_scaffold, active_test_scaffold, inactive_test_scaffold\n",
    "active_train_rdk7, inactive_train_rdk7, active_valid_rdk7, inactive_valid_rdk7, active_test_rdk7, inactive_test_rdk7 = extract_scaffold(rdk7_train, rdk7_valid, rdk7_test)\n",
    "scaffold_train = pd.concat([active_train_rdk7, inactive_train_rdk7], axis = 0).reset_index(drop=True)\n",
    "scaffold_valid = pd.concat([active_valid_rdk7, inactive_valid_rdk7], axis = 0).reset_index(drop=True)\n",
    "scaffold_test = pd.concat([active_test_rdk7, inactive_test_rdk7], axis = 0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold_train.to_csv(\"./data/Official/Featurizer_data/scaffold_train.csv\", index = False)\n",
    "scaffold_valid.to_csv(\"./data/Official/Featurizer_data/scaffold_valid.csv\", index = False)\n",
    "scaffold_test.to_csv(\"./data/Official/Featurizer_data/scaffold_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheminformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
